import pandas as pd
import numpy as np
import os
import joblib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline

# ================= ì„¤ì • =================
DATA_DIR = "data"
SAVE_DIR = "features"

# [ìˆ˜ì •] í™•ì¸ëœ ì‹¤ì œ 'generator' ì´ë¦„ë“¤ì„ ì •í™•íˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ì˜
MISTRAL_LIST = [
    'mistralai/Devstral-Small-2505',
    'mistralai/Mistral-7B-Instruct-v0.3'
]

GRANITE_LIST = [
    'ibm-granite/granite-3.3-8b-instruct',
    'ibm-granite/granite-3.2-2b-instruct',
    'ibm-granite/granite-3.3-8b-base'
]

# ë‘ ë¦¬ìŠ¤íŠ¸ë¥¼ í•©ì³ì„œ "ê´€ì‹¬ ëŒ€ìƒ" ì •ì˜
TARGET_GENERATORS = MISTRAL_LIST + GRANITE_LIST

def load_data(filename):
    path = os.path.join(DATA_DIR, filename)
    if not os.path.exists(path):
        raise FileNotFoundError(f"âŒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {path}")
    df = pd.read_parquet(path)
    # ì»¬ëŸ¼ ì´ë¦„ ë°©ì–´ ë¡œì§
    if 'code' not in df.columns and 'text' in df.columns:
        df['code'] = df['text']
    return df

# 1. ë°ì´í„° ë¡œë“œ
print("ğŸ“‚ Loading Data...")
train_df = load_data("task_b_training_set.parquet")
val_df = load_data("task_b_validation_set.parquet")

# 2. Specialist í•™ìŠµ ë°ì´í„° í•„í„°ë§
print("ğŸ› ï¸ Training TF-IDF Specialist...")
print(f"   - Target Mistral models: {len(MISTRAL_LIST)} types")
print(f"   - Target Granite models: {len(GRANITE_LIST)} types")

# generator ì»¬ëŸ¼ì´ íƒ€ê²Ÿ ë¦¬ìŠ¤íŠ¸ì— í¬í•¨ëœ í–‰ë§Œ ì¶”ì¶œ
mask = train_df['generator'].isin(TARGET_GENERATORS)
spec_train = train_df[mask].copy()

print(f"   - Selected {len(spec_train)} samples for specialist training.")

if len(spec_train) == 0:
    print("âŒ ì˜¤ë¥˜: ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤! generator ì»¬ëŸ¼ ë‚´ìš©ì„ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”.")
    exit()

# 3. ë¼ë²¨ ìƒì„± (Granite=0, Mistral=1)
# generator ì´ë¦„ì´ MISTRAL_LISTì— ìˆìœ¼ë©´ 1, ì•„ë‹ˆë©´(GRANITEë©´) 0
y_train = spec_train['generator'].apply(lambda x: 1 if x in MISTRAL_LIST else 0)

# 4. íŒŒì´í”„ë¼ì¸ í•™ìŠµ (TF-IDF + Random Forest)
pipeline = Pipeline([
    # max_featuresë¥¼ ëŠ˜ë ¤ì„œ ë” ë¯¸ì„¸í•œ íŠ¹ì§•ê¹Œì§€ ì¡ë„ë¡ í•¨
    ('tfidf', TfidfVectorizer(max_features=5000, token_pattern=r'\b\w+\b')),
    ('clf', RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42))
])

pipeline.fit(spec_train['code'].fillna(""), y_train)
print("âœ… Training Complete!")

# 5. ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ í™•ë¥  ì¶”ì¶œ ë° ì €ì¥ í•¨ìˆ˜
def save_tfidf_probs(df, filename):
    print(f"ğŸ’‰ Injecting features for {filename}...")
    texts = df['code'].fillna("")
    
    # í™•ë¥  ì˜ˆì¸¡ (Class 0: Granite, Class 1: Mistral)
    probs = pipeline.predict_proba(texts)
    
    out_df = pd.DataFrame()
    out_df['tfidf_prob_granit'] = probs[:, 0]
    out_df['tfidf_prob_mistral'] = probs[:, 1]
    
    # ì €ì¥
    if not os.path.exists(SAVE_DIR):
        os.makedirs(SAVE_DIR)
    
    save_path = os.path.join(SAVE_DIR, f"tfidf_{filename}")
    out_df.to_parquet(save_path)
    print(f"âœ… Saved to {save_path}")

# ì‹¤í–‰: Train / Val / Test
save_tfidf_probs(train_df, "train.parquet")
save_tfidf_probs(val_df, "val.parquet")

if os.path.exists(os.path.join(DATA_DIR, "test.parquet")):
    test_df = load_data("test.parquet")
    save_tfidf_probs(test_df, "test.parquet")